{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109},{"sourceId":12725403,"sourceType":"datasetVersion","datasetId":8041590}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, cv2, random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimport pandas as pd\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.applications import ResNet50, VGG16, EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-10T12:10:47.350044Z","iopub.execute_input":"2025-08-10T12:10:47.350334Z","iopub.status.idle":"2025-08-10T12:11:00.654927Z","shell.execute_reply.started":"2025-08-10T12:10:47.350311Z","shell.execute_reply":"2025-08-10T12:11:00.654340Z"}},"outputs":[{"name":"stderr","text":"2025-08-10 12:10:49.943433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754827850.123420      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754827850.174921      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"DATASET_DIR = \"/kaggle/input/utkface-new/UTKFace\"\n\nfile_list = [\n    os.path.join(DATASET_DIR, f)\n    for f in os.listdir(DATASET_DIR)\n    if f.lower().endswith(\".jpg\")\n]\n\nrandom_file = random.choice(file_list)\nparts = os.path.basename(random_file).split(\"_\")\nage = int(parts[0])\ngender = \"Male\" if int(parts[1]) == 0 else \"Female\"\n\nimg = cv2.imread(random_file)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(img)\nplt.title(f\"Age: {age}, Gender: {gender}\")\nplt.axis('off')\nplt.show()\n\nprint(f\"File: {os.path.basename(random_file)}\")\nprint(f\"Age: {age}\")\nprint(f\"Gender: {gender}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"male_count = 0\nfemale_count = 0\n\nfor filename in os.listdir(DATASET_DIR):\n    if filename.endswith(\".jpg\"):\n        try:\n            gender = int(filename.split(\"_\")[1])\n            if gender == 0:\n                male_count += 1\n            elif gender == 1:\n                female_count += 1\n        except:\n            continue\nprint(f\"Tổng số ảnh: {male_count + female_count}\")\nprint(f\"Số nam   : {male_count}\")\nprint(f\"Số nữ    : {female_count}\")\n\nlabels = ['Male', 'Female']\ncounts = [male_count, female_count]\n\nplt.bar(labels, counts, color=['blue', 'pink'])\nplt.title(\"Gender Distribution in UTKFace\")\nplt.ylabel(\"Số lượng ảnh\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:34:24.317826Z","iopub.execute_input":"2025-08-08T09:34:24.318092Z","iopub.status.idle":"2025-08-08T09:34:24.458913Z","shell.execute_reply.started":"2025-08-08T09:34:24.318073Z","shell.execute_reply":"2025-08-08T09:34:24.458256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ages = []\n\nfor filename in os.listdir(DATASET_DIR):\n    if filename.endswith(\".jpg\"):\n        try:\n            age = int(filename.split(\"_\")[0])\n            ages.append(age)\n        except:\n            continue  # bỏ qua file lỗi\n\nplt.figure(figsize=(10, 5))\nplt.hist(ages, bins=range(0, 101, 5), color='skyblue', edgecolor='black')\nplt.title(\"Phân bố tuổi trong UTKFace\")\nplt.xlabel(\"Tuổi\")\nplt.ylabel(\"Số lượng ảnh\")\nplt.grid(True)\nplt.xticks(range(0, 101, 5))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:34:32.033860Z","iopub.execute_input":"2025-08-08T09:34:32.034121Z","iopub.status.idle":"2025-08-08T09:34:32.292165Z","shell.execute_reply.started":"2025-08-08T09:34:32.034102Z","shell.execute_reply":"2025-08-08T09:34:32.291497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_files, temp_files = train_test_split(file_list, test_size=0.3, random_state=42)\n\nval_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n\nprint(f\"Tổng ảnh     : {len(file_list)}\")\nprint(f\"Train ảnh    : {len(train_files)}\")\nprint(f\"Validation ảnh: {len(val_files)}\")\nprint(f\"Test ảnh     : {len(test_files)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:37:07.361444Z","iopub.execute_input":"2025-08-08T09:37:07.361734Z","iopub.status.idle":"2025-08-08T09:37:07.382152Z","shell.execute_reply.started":"2025-08-08T09:37:07.361714Z","shell.execute_reply":"2025-08-08T09:37:07.381432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MAX_AGE = 116\n\ndef load_and_preprocess(file_name, img_size=128):\n    file_path = os.path.join(DATASET_DIR, file_name)\n    img = cv2.imread(file_path)\n    if img is None:\n        raise ValueError(f\"Không đọc được file ảnh: {file_path}\")\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # đổi BGR sang RGB\n    img = cv2.resize(img, (img_size, img_size))\n    img = img.astype(np.float32)\n    return img\n\n\ndef extract_labels_from_filename(file_path):\n    # filename có dạng: age_gender_race_date.jpg.chip.jpg\n    base = os.path.basename(file_path)\n    parts = base.split('_')\n    age = int(parts[0])\n    gender = int(parts[1])  # 0 = Male, 1 = Female\n    age = age / MAX_AGE\n    return gender, age","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:34:36.886176Z","iopub.execute_input":"2025-08-08T09:34:36.886773Z","iopub.status.idle":"2025-08-08T09:34:36.891993Z","shell.execute_reply.started":"2025-08-08T09:34:36.886747Z","shell.execute_reply":"2025-08-08T09:34:36.891197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef create_datagen(augment=False):\n    if augment:\n        return ImageDataGenerator(\n            rescale=1./255,\n            rotation_range=20,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            horizontal_flip=True,\n            zoom_range=0.1,\n            fill_mode='nearest'\n        )\n    else:\n        return ImageDataGenerator(rescale=1./255)\n\ntrain_datagen = create_datagen(augment=True)\nval_datagen = create_datagen(augment=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:36:04.417101Z","iopub.execute_input":"2025-08-08T09:36:04.417372Z","iopub.status.idle":"2025-08-08T09:36:04.422115Z","shell.execute_reply.started":"2025-08-08T09:36:04.417353Z","shell.execute_reply":"2025-08-08T09:36:04.421503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def multi_output_generator(file_list, datagen, batch_size=32, img_size=128, shuffle=True):\n    while True:\n        if shuffle:\n            random.shuffle(file_list)\n        for i in range(0, len(file_list), batch_size):\n            batch_files = file_list[i:i+batch_size]\n            batch_images = []\n            gender_labels = []\n            age_labels = []\n\n            for file in batch_files:\n                img = load_and_preprocess(file, img_size)\n                gender, age = extract_labels_from_filename(file)\n                batch_images.append(img)\n                gender_labels.append(gender)\n                age_labels.append(age)\n\n            batch_images = np.array(batch_images)\n\n            batch_images_aug_iter = datagen.flow(batch_images, batch_size=len(batch_images), shuffle=False)\n            batch_images_aug = next(batch_images_aug_iter)\n\n            yield batch_images_aug, {\n                'gender_output': np.array(gender_labels),\n                'age_output': np.array(age_labels, dtype=np.float32)\n            }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:36:06.403476Z","iopub.execute_input":"2025-08-08T09:36:06.404182Z","iopub.status.idle":"2025-08-08T09:36:06.409466Z","shell.execute_reply.started":"2025-08-08T09:36:06.404157Z","shell.execute_reply":"2025-08-08T09:36:06.408698Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\nMAX_AGE = 116\n\ndef extract_labels_from_filename(file_path):\n    base = tf.strings.split(file_path, os.sep)[-1]\n    parts = tf.strings.split(base, '_')\n    age = tf.strings.to_number(parts[0], out_type=tf.float32) / MAX_AGE\n    gender = tf.strings.to_number(parts[1], out_type=tf.float32)\n    return gender, age\n\ndef load_and_preprocess(file_path, img_size=128):\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [img_size, img_size])\n    img = tf.cast(img, tf.float32) / 255.0\n    gender, age = extract_labels_from_filename(file_path)\n    return img, {'gender_output': gender, 'age_output': age}\n\ndef augment(img, labels):\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, max_delta=0.1)\n    img = tf.image.random_contrast(img, lower=0.9, upper=1.1)\n    img = tf.image.random_saturation(img, lower=0.9, upper=1.1)\n    img = tf.image.random_hue(img, max_delta=0.02)\n    return img, labels\n\ndef create_dataset(file_list, batch_size=64, augment_data=False, shuffle=True):\n    ds = tf.data.Dataset.from_tensor_slices(file_list)\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(file_list))\n    ds = ds.map(lambda x: load_and_preprocess(x, 128), num_parallel_calls=tf.data.AUTOTUNE)\n    if augment_data:\n        ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return ds\n\n# Thay thế train_gen / val_gen\ntrain_gen = create_dataset(train_files, batch_size=64, augment_data=True, shuffle=True)\nval_gen = create_dataset(val_files, batch_size=64, augment_data=False, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_gen = multi_output_generator(train_files, train_datagen, batch_size=32, img_size=128, shuffle=True)\n# val_gen = multi_output_generator(val_files, val_datagen, batch_size=32, img_size=128, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T09:37:16.281666Z","iopub.execute_input":"2025-08-08T09:37:16.281929Z","iopub.status.idle":"2025-08-08T09:37:16.286187Z","shell.execute_reply.started":"2025-08-08T09:37:16.281910Z","shell.execute_reply":"2025-08-08T09:37:16.285505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_model(base_model_class, pooling_mode='avg'):\n    if pooling_mode == 'flatten':\n        base_model = base_model_class(\n            include_top=False,\n            input_shape=(128, 128, 3),\n            weights='imagenet'\n        )\n        x = layers.Flatten()(base_model.output)\n    else:\n        base_model = base_model_class(\n            include_top=False,\n            input_shape=(128, 128, 3),\n            pooling=pooling_mode,\n            weights='imagenet'\n        )\n        x = base_model.output\n\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n\n    gender_output = layers.Dense(1, activation='sigmoid', name='gender_output')(x)\n    age_output = layers.Dense(1, activation='linear', name='age_output')(x)\n\n    model = Model(inputs=base_model.input, outputs=[gender_output, age_output])\n    model.compile(\n        optimizer='adam',\n        loss={\n            'gender_output': 'binary_crossentropy',\n            'age_output': 'mse'\n        },\n        metrics={\n            'gender_output': 'accuracy',\n            'age_output': 'mae'\n        }\n    )\n    return model\n\ndef train_and_save(model, name, train_gen, val_gen, output_dir=\"/kaggle/working\"):\n    early_stop = EarlyStopping(\n        monitor='val_loss',\n        patience=29,\n        restore_best_weights=True\n    )\n\n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=30,\n        callbacks=[early_stop],\n        verbose=1\n    )\n\n    pd.DataFrame(history.history).to_csv(f\"{output_dir}/{name}_history.csv\", index=False)\n    model.save(f\"{output_dir}/{name}_model.h5\")\n    print(f\"✅ {name} đã lưu model & history.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"===== Training ResNet50 =====\")\nmodel_resnet = build_model(ResNet50, pooling_mode='avg')\ntrain_and_save(model_resnet, \"ResNet50\", train_gen, val_gen)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"===== Training VGG16 =====\")\nmodel_vgg = build_model(VGG16, pooling_mode='flatten')\ntrain_and_save(model_vgg, \"VGG16\", train_gen, val_gen)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"===== Training EfficientNetB0 =====\")\nmodel_eff = build_model(EfficientNetB0, pooling_mode='avg')\ntrain_and_save(model_eff, \"EfficientNetB0\", train_gen, val_gen)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\n# File paths\nfiles = {\n    \"EfficientNetB0\": \"/kaggle/input/my-results/EfficientNetB0_history.csv\",\n    \"ResNet50\": \"/kaggle/input/my-results/ResNet50_history.csv\",\n    \"VGG16\": \"/kaggle/input/my-results/VGG16_history.csv\"\n}\n\n# Thư mục lưu ảnh\nsave_dir = \"./plots\"\nos.makedirs(save_dir, exist_ok=True)\n\nfor name, path in files.items():\n    df = pd.read_csv(path)\n    \n    # ---- Plot Accuracy ----\n    plt.figure(figsize=(8, 5))\n    plt.plot(df['gender_output_accuracy'], label='Train Acc')\n    plt.plot(df['val_gender_output_accuracy'], linestyle='--', label='Val Acc')\n    plt.title(f'{name} - Gender Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f\"{name}_accuracy.png\"))\n    plt.close()\n    \n    # ---- Plot Loss ----\n    plt.figure(figsize=(8, 5))\n    plt.plot(df['loss'], label='Train Loss')\n    plt.plot(df['val_loss'], linestyle='--', label='Val Loss')\n    plt.title(f'{name} - Overall Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(os.path.join(save_dir, f\"{name}_loss.png\"))\n    plt.close()\n\nprint(f\"✅ Đã lưu biểu đồ vào thư mục: {save_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T12:04:38.275168Z","iopub.execute_input":"2025-08-10T12:04:38.275440Z","iopub.status.idle":"2025-08-10T12:04:39.353686Z","shell.execute_reply.started":"2025-08-10T12:04:38.275416Z","shell.execute_reply":"2025-08-10T12:04:39.352908Z"}},"outputs":[{"name":"stdout","text":"✅ Đã lưu biểu đồ vào thư mục: ./plots\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport os\n\nfiles = {\n    \"EfficientNetB0\": \"/kaggle/input/my-results/EfficientNetB0_history.csv\",\n    \"ResNet50\": \"/kaggle/input/my-results/ResNet50_history.csv\",\n    \"VGG16\": \"/kaggle/input/my-results/VGG16_history.csv\"\n}\n\nsave_dir = \"./plots_compare\"\nos.makedirs(save_dir, exist_ok=True)\n\nhistories = {name: pd.read_csv(path) for name, path in files.items()}\n\n# ==== Train Accuracy ====\nplt.figure(figsize=(8, 5))\nfor name, df in histories.items():\n    plt.plot(df['gender_output_accuracy'], label=name)\nplt.title(\"Train Accuracy (Gender)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"train_accuracy.png\"))\nplt.close()\n\n# ==== Val Accuracy ====\nplt.figure(figsize=(8, 5))\nfor name, df in histories.items():\n    plt.plot(df['val_gender_output_accuracy'], label=name)\nplt.title(\"Validation Accuracy (Gender)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"val_accuracy.png\"))\nplt.close()\n\n# ==== Train Loss ====\nplt.figure(figsize=(8, 5))\nfor name, df in histories.items():\n    plt.plot(df['loss'], label=name)\nplt.title(\"Train Loss (Overall)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"train_loss.png\"))\nplt.close()\n\n# ==== Val Loss ====\nplt.figure(figsize=(8, 5))\nfor name, df in histories.items():\n    plt.plot(df['val_loss'], label=name)\nplt.title(\"Validation Loss (Overall)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"val_loss.png\"))\nplt.close()\n\nprint(f\"✅ Đã lưu các biểu đồ so sánh vào thư mục: {save_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T12:06:14.628607Z","iopub.execute_input":"2025-08-10T12:06:14.628894Z","iopub.status.idle":"2025-08-10T12:06:15.393470Z","shell.execute_reply.started":"2025-08-10T12:06:14.628874Z","shell.execute_reply":"2025-08-10T12:06:15.392586Z"}},"outputs":[{"name":"stdout","text":"✅ Đã lưu các biểu đồ so sánh vào thư mục: ./plots_compare\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"MAX_AGE = 116 \n\nDATASET_DIR = \"/kaggle/input/utkface-new/UTKFace\"\nmodel_paths = {\n    \"EfficientNetB0\": \"/kaggle/input/my-results/EfficientNetB0_model.h5\",\n    \"ResNet50\": \"/kaggle/input/my-results/ResNet50_model.h5\",\n    \"VGG16\": \"/kaggle/input/my-results/VGG16_model.h5\"\n}\n\ntest_files = [\n    os.path.join(DATASET_DIR, f)\n    for f in os.listdir(DATASET_DIR)\n    if f.lower().endswith(\".jpg\")\n]\n\ntest_gen = create_dataset(test_files, batch_size=64, augment_data=False, shuffle=False)\n\ncustom_objects = {\n    \"mse\": tf.keras.losses.MeanSquaredError(),\n    \"mae\": tf.keras.losses.MeanAbsoluteError()\n}\n\nfor name, model_path in model_paths.items():\n    print(f\"🔍 Đang đánh giá {name}...\")\n    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n    results = model.evaluate(test_gen, verbose=1)\n    print(\"Test loss and metrics:\", results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T12:30:23.356365Z","iopub.execute_input":"2025-08-10T12:30:23.356603Z","iopub.status.idle":"2025-08-10T12:32:07.794933Z","shell.execute_reply.started":"2025-08-10T12:30:23.356587Z","shell.execute_reply":"2025-08-10T12:32:07.794328Z"}},"outputs":[{"name":"stdout","text":"🔍 Đang đánh giá EfficientNetB0...\n\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - age_output_loss: 0.0243 - age_output_mean_absolute_error: 0.1164 - gender_output_accuracy: 0.7966 - gender_output_loss: 0.4385 - loss: 0.4628\nTest loss and metrics: [0.4640033543109894, 0.4398691952228546, 0.024005640298128128, 0.11607392877340317, 0.7962291240692139]\n🔍 Đang đánh giá ResNet50...\n\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 62ms/step - age_output_loss: 0.0100 - age_output_mean_absolute_error: 0.0784 - gender_output_accuracy: 0.9414 - gender_output_loss: 0.1486 - loss: 0.1586\nTest loss and metrics: [0.16278740763664246, 0.15308408439159393, 0.00978559534996748, 0.07761602848768234, 0.9399358630180359]\n🔍 Đang đánh giá VGG16...\n\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 125ms/step - age_output_loss: 0.0171 - age_output_mean_absolute_error: 0.0980 - gender_output_accuracy: 0.9114 - gender_output_loss: 0.2074 - loss: 0.2245\nTest loss and metrics: [0.22372928261756897, 0.20685997605323792, 0.016798432916402817, 0.09734412282705307, 0.9119706153869629]\n","output_type":"stream"}],"execution_count":18}]}